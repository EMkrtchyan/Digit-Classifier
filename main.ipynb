{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset to tensor transform object\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#Loading train and test set and making train/testloader objects for training/testing with batch size\n",
    "batch_size = 128\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "train_X = torch.stack([trainset[i][0] for i in range(len(trainset))]).to(device)\n",
    "train_y = torch.tensor([trainset[i][1] for i in range(len(trainset))]).to(device)\n",
    "\n",
    "test_X = torch.stack([testset[i][0] for i in range(len(testset))]).to(device)\n",
    "test_y = torch.tensor([testset[i][1] for i in range(len(testset))]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOSklEQVR4nO3cbWjV9fvA8es4Z1mB1XJhRcUyKyujMoswsjBnZKYgGRQllEH1QGhlN5TWgwijGynDhBQzC0RdYij5pIwC00S0GxyZZVFs6pRuJLr1/B/86aLSct/z23Gbvl7Qk+P32rkmtbefLT+lcrlcDgCIiF5dvQAA3YcoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIocEjatm1blEqlePrppzvtY65evTpKpVKsXr260z4mdDeiQLcxf/78KJVKsX79+q5epSqam5tj4sSJ0dDQEEcddVScddZZ0dTUFN99911Xrwapd1cvAIeLO++8M0466aS45ZZb4tRTT42PP/44Zs2aFStXrowNGzZE3759u3pFEAU4WJYsWRIjRoz422sXX3xx3HbbbfHaa6/FHXfc0TWLwV/49hE9yq+//hrTpk2Liy++OPr16xdHH310XHHFFfHOO+/868xzzz0Xp512WvTt2zeuvPLK+OSTT/Z5pqWlJSZMmBDHH398HHnkkTF06NBYvnz5Aff56aefoqWlJdrb2w/47D+DEBExfvz4iIjYvHnzAefhYBAFepQffvghXn755RgxYkTMmDEjHnvssdi5c2c0NjbGxo0b93l+wYIF8fzzz8c999wTDz30UHzyySdx9dVXx/bt2/OZTz/9NC677LLYvHlzPPjgg/HMM8/E0UcfHePGjYs33njjP/dZt25dnHPOOTFr1qyKPp+2traIiDjhhBMqmofO5ttH9CjHHXdcbNu2Lfr06ZOvTZ48Oc4+++x44YUXYu7cuX97/vPPP48tW7bEySefHBERo0ePjksvvTRmzJgRzz77bERETJkyJU499dT48MMP44gjjoiIiLvvvjuGDx8eDzzwQP5pvhpmzJgRNTU1MWHChKq9BxThpECPUlNTk0HYu3dv7N69O37//fcYOnRobNiwYZ/nx40bl0GIiBg2bFhceumlsXLlyoiI2L17d7z99ttx4403xo8//hjt7e3R3t4eu3btisbGxtiyZUt8++23/7rPiBEjolwux2OPPVb4c3n99ddj7ty50dTUFGeeeWbheagGUaDHeeWVV2LIkCFx5JFHRl1dXfTv3z9WrFgR33///T7P7u+L7aBBg2Lbtm0R8f8niXK5HI8++mj079//b/9Mnz49IiJ27NjR6Z/De++9F7fffns0NjbGE0880ekfHyrl20f0KAsXLoxJkybFuHHj4v7774/6+vqoqamJJ598MrZu3Vr44+3duzciIu67775obGzc7zMDBw78n3b+p02bNsXYsWPjvPPOiyVLlkTv3v4zpPvwbyM9ypIlS6KhoSGam5ujVCrl63/+qf6ftmzZss9rn332WZx++ukREdHQ0BAREbW1tTFy5MjOX/gftm7dGqNHj476+vpYuXJlHHPMMVV/TyjCt4/oUWpqaiIiolwu52tr166NNWvW7Pf5ZcuW/e1nAuvWrYu1a9fGtddeGxER9fX1MWLEiJgzZ060trbuM79z587/3KfI/5La1tYWo0aNil69esWqVauif//+B5yBg81JgW5n3rx58dZbb+3z+pQpU2LMmDHR3Nwc48ePj+uuuy6+/PLLeOmll2Lw4MGxZ8+efWYGDhwYw4cPj7vuuit++eWXmDlzZtTV1cXUqVPzmRdffDGGDx8e559/fkyePDkaGhpi+/btsWbNmvjmm29i06ZN/7rrunXr4qqrrorp06cf8IfNo0ePji+++CKmTp0a77//frz//vv5ayeeeGJcc801HfjdgeoSBbqd2bNn7/f1SZMmxaRJk6KtrS3mzJkTq1atisGDB8fChQtj8eLF+72o7tZbb41evXrFzJkzY8eOHTFs2LCYNWtWDBgwIJ8ZPHhwrF+/Ph5//PGYP39+7Nq1K+rr6+PCCy+MadOmddrn9WdcnnrqqX1+7corrxQFuoVS+a/ncAAOa36mAEASBQCSKACQRAGAJAoAJFEAIHX47yn89UoBAHqejvwNBCcFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASL27egF6pvvuu6/wTN++fSt6ryFDhhSemTBhQkXvVdTs2bMLz6xZs6ai93r11VcrmoMinBQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBK5XK53KEHS6Vq70IXWbRoUeGZg3Xh3KFo69atFc2NHDmy8MzXX39d0XtxaOrIl3snBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApN5dvQCd61C83K6lpaXwzKpVqwrPNDQ0FJ65/vrrC8+cccYZhWciIm6++ebCM08++WRF78Xhy0kBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJhXjd1NChQyuaGz9+fCdvsn+ffvpp4ZmxY8dW9F7t7e2FZ/bs2VN4pk+fPoVnPvjgg8IzF1xwQeGZiIi6urqK5qAIJwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQX4nVTAwYMqGiuVCoVnqnkcrvGxsbCM62trYVnDqampqbCM4MHD67CJvu3YsWKg/ZeHL6cFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgOSW1G7qzTffrGhu4MCBhWd+/PHHwjO7d+8uPNPd3XTTTYVnamtrq7AJdB0nBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJBfiHWK++uqrrl6hW7j//vsLzwwaNKgKm+xr7dq1B3UOinBSACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAKpXL5XKHHiyVqr0L7NeYMWMKzyxevLjwTJ8+fQrP7Nixo/DMTTfdVHgmIuLdd9+taA7+1JEv904KACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIvbt6ATiQoUOHFp6p5HK7SixatKjwjIvt6M6cFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgOSWVA6aZcuWVTQ3atSozl3kXyxYsKDwzCOPPFKFTaDrOCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCVyuVyuUMPlkrV3oUeZMCAAYVnNm3aVNF71dXVFZ5pb28vPHP55ZcXntm6dWvhGegqHfly76QAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDUu6sXoGdaunRp4ZlKLrar1MKFCwvPuNwOnBQA+AtRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABILsQjxo4dW3jmoosuqsIm+7d69erCM9OnT+/8ReAw4KQAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkQrxDTF1dXeGZhx9+uPBMbW1t4ZlKbdy4sfDMnj17On8ROAw4KQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAMktqYeYpqamwjOXXHJJFTbZ17Jlyyqamz59eucuAvwrJwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKRSuVwud+jBUqnau9AJfv7558IztbW1VdhkX6ecckpFc62trZ28CRyeOvLl3kkBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpd1cvwOHj+OOPr2jut99+6+RNutb3339f0Vwlvw+VXHbYr1+/wjOVOPbYYyuau/feezt3kU70xx9/VDT3wAMPFJ756aefKnqvA3FSACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAciEeB81HH33U1St0C4sXL65orrW1tfDMiSeeWHhm4sSJhWf437S1tRWeeeKJJ6qwiZMCAH8hCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAqVQul8sderBUqvYudILm5ubCMzfccEMVNuFw8vvvvxee2bt3bxU22b/ly5cXnlm/fn0VNtm/9957r/DMBx98UHimI1/unRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkllRi6tSphWdqa2ursEnnOffccwvPTJw4sQqbdJ558+YVntm2bVvnL7IfS5cuLTzT0tJShU34L25JBaAQUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASC7EAzhMuBAPgEJEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJB6d/TBcrlczT0A6AacFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABI/wfISJzDX/e8sAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = testset[1]\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f'Label: {label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size = 28*28, output_size = 10, hidden_size=128,ker_size = 3, out_chan=16):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=out_chan,kernel_size=ker_size)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(2704,hidden_size)\n",
    "        print(out_chan*((input_size-ker_size+1)//2)**2)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2446096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2704, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "Xs = trainset.data.float()\n",
    "Xs = torch.reshape(Xs,(60000,1,28,28))\n",
    "print(Xs.shape)\n",
    "Xs = Xs.to(device)\n",
    "ys = trainset.targets\n",
    "ys = F.one_hot(ys,10).float()\n",
    "ys = ys.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.4915\n",
      "Epoch 2/100, Loss: 0.2180\n",
      "Epoch 3/100, Loss: 0.1552\n",
      "Epoch 4/100, Loss: 0.1220\n",
      "Epoch 5/100, Loss: 0.1062\n",
      "Epoch 6/100, Loss: 0.0930\n",
      "Epoch 7/100, Loss: 0.0839\n",
      "Epoch 8/100, Loss: 0.0764\n",
      "Epoch 9/100, Loss: 0.0700\n",
      "Epoch 10/100, Loss: 0.0646\n",
      "Epoch 11/100, Loss: 0.0595\n",
      "Epoch 12/100, Loss: 0.0560\n",
      "Epoch 13/100, Loss: 0.0534\n",
      "Epoch 14/100, Loss: 0.0479\n",
      "Epoch 15/100, Loss: 0.0489\n",
      "Epoch 16/100, Loss: 0.0448\n",
      "Epoch 17/100, Loss: 0.0423\n",
      "Epoch 18/100, Loss: 0.0404\n",
      "Epoch 19/100, Loss: 0.0391\n",
      "Epoch 20/100, Loss: 0.0360\n",
      "Epoch 21/100, Loss: 0.0347\n",
      "Epoch 22/100, Loss: 0.0338\n",
      "Epoch 23/100, Loss: 0.0331\n",
      "Epoch 24/100, Loss: 0.0318\n",
      "Epoch 25/100, Loss: 0.0298\n",
      "Epoch 26/100, Loss: 0.0288\n",
      "Epoch 27/100, Loss: 0.0297\n",
      "Epoch 28/100, Loss: 0.0260\n",
      "Epoch 29/100, Loss: 0.0248\n",
      "Epoch 30/100, Loss: 0.0252\n",
      "Epoch 31/100, Loss: 0.0249\n",
      "Epoch 32/100, Loss: 0.0241\n",
      "Epoch 33/100, Loss: 0.0223\n",
      "Epoch 34/100, Loss: 0.0237\n",
      "Epoch 35/100, Loss: 0.0223\n",
      "Epoch 36/100, Loss: 0.0221\n",
      "Epoch 37/100, Loss: 0.0219\n",
      "Epoch 38/100, Loss: 0.0196\n",
      "Epoch 39/100, Loss: 0.0193\n",
      "Epoch 40/100, Loss: 0.0198\n",
      "Epoch 41/100, Loss: 0.0195\n",
      "Epoch 42/100, Loss: 0.0175\n",
      "Epoch 43/100, Loss: 0.0171\n",
      "Epoch 44/100, Loss: 0.0177\n",
      "Epoch 45/100, Loss: 0.0189\n",
      "Epoch 46/100, Loss: 0.0167\n",
      "Epoch 47/100, Loss: 0.0154\n",
      "Epoch 48/100, Loss: 0.0163\n",
      "Epoch 49/100, Loss: 0.0171\n",
      "Epoch 50/100, Loss: 0.0157\n",
      "Epoch 51/100, Loss: 0.0163\n",
      "Epoch 52/100, Loss: 0.0157\n",
      "Epoch 53/100, Loss: 0.0145\n",
      "Epoch 54/100, Loss: 0.0144\n",
      "Epoch 55/100, Loss: 0.0141\n",
      "Epoch 56/100, Loss: 0.0160\n",
      "Epoch 57/100, Loss: 0.0141\n",
      "Epoch 58/100, Loss: 0.0150\n",
      "Epoch 59/100, Loss: 0.0138\n",
      "Epoch 60/100, Loss: 0.0147\n",
      "Epoch 61/100, Loss: 0.0135\n",
      "Epoch 62/100, Loss: 0.0138\n",
      "Epoch 63/100, Loss: 0.0139\n",
      "Epoch 64/100, Loss: 0.0134\n",
      "Epoch 65/100, Loss: 0.0131\n",
      "Epoch 66/100, Loss: 0.0132\n",
      "Epoch 67/100, Loss: 0.0135\n",
      "Epoch 68/100, Loss: 0.0123\n",
      "Epoch 69/100, Loss: 0.0116\n",
      "Epoch 70/100, Loss: 0.0127\n",
      "Epoch 71/100, Loss: 0.0122\n",
      "Epoch 72/100, Loss: 0.0117\n",
      "Epoch 73/100, Loss: 0.0125\n",
      "Epoch 74/100, Loss: 0.0135\n",
      "Epoch 75/100, Loss: 0.0107\n",
      "Epoch 76/100, Loss: 0.0103\n",
      "Epoch 77/100, Loss: 0.0116\n",
      "Epoch 78/100, Loss: 0.0113\n",
      "Epoch 79/100, Loss: 0.0109\n",
      "Epoch 80/100, Loss: 0.0122\n",
      "Epoch 81/100, Loss: 0.0124\n",
      "Epoch 82/100, Loss: 0.0116\n",
      "Epoch 83/100, Loss: 0.0115\n",
      "Epoch 84/100, Loss: 0.0115\n",
      "Epoch 85/100, Loss: 0.0099\n",
      "Epoch 86/100, Loss: 0.0113\n",
      "Epoch 87/100, Loss: 0.0111\n",
      "Epoch 88/100, Loss: 0.0101\n",
      "Epoch 89/100, Loss: 0.0101\n",
      "Epoch 90/100, Loss: 0.0097\n",
      "Epoch 91/100, Loss: 0.0112\n",
      "Epoch 92/100, Loss: 0.0106\n",
      "Epoch 93/100, Loss: 0.0105\n",
      "Epoch 94/100, Loss: 0.0097\n",
      "Epoch 95/100, Loss: 0.0105\n",
      "Epoch 96/100, Loss: 0.0100\n",
      "Epoch 97/100, Loss: 0.0092\n",
      "Epoch 98/100, Loss: 0.0102\n",
      "Epoch 99/100, Loss: 0.0098\n",
      "Epoch 100/100, Loss: 0.0105\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i in range(0, len(train_X), batch_size):\n",
    "        # Get the batch\n",
    "        batch_X = train_X[i:i + batch_size]\n",
    "        batch_y = train_y[i:i + batch_size]\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / (len(train_X) / batch_size)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 98.69%\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for i in range(0, len(test_X), batch_size):\n",
    "        # Get the batch\n",
    "        batch_X = test_X[i:i + batch_size]\n",
    "        batch_y = test_y[i:i + batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open(\"3.png\")\n",
    "\n",
    "transform = transforms.Compose([transforms.PILToTensor()])\n",
    "\n",
    "imTensor =  transform(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imTensor  = imTensor.reshape(3,1,28,28)\n",
    "imTensor = imTensor.float()\n",
    "imTensor.shape\n",
    "imTensor = imTensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(imTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"./weights/model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
